{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab1-1-introduction_to_keras-student.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["mRICWP_PBn8W","4m3fXuYmBn8Z"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"bxKTtTjFBn4I","colab_type":"text"},"cell_type":"markdown","source":["# Lab 1 Introduction to Keras"]},{"metadata":{"id":"uO9KRqHMBn4N","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from keras.datasets import mnist\n","from keras.models import Sequential, Model\n","from keras.layers.core import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, Input\n","from keras.utils import np_utils\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import EarlyStopping\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7-FsMIaFBn4u","colab_type":"text"},"cell_type":"markdown","source":["# Loading train data"]},{"metadata":{"id":"NHZB0oJ3Bn40","colab_type":"code","colab":{}},"cell_type":"code","source":["nb_classes = 10\n","\n","# the data, shuffled and split between tran and test sets\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","print(\"X_train original shape\", X_train.shape)\n","print(\"y_train original shape\", y_train.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JAsAguqHBn5G","colab_type":"code","colab":{}},"cell_type":"code","source":["for i in range(6):\n","    plt.subplot(3,3,i+1)\n","    plt.imshow(X_train[i], cmap='gray', interpolation='none')\n","    plt.title(\"Class {}\".format(y_train[i]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"S2Tpw00eBn5P","colab_type":"text"},"cell_type":"markdown","source":["# Format the data for training\n","Our neural-network is going to take a single vector for each training example, so we need to reshape the input so that each 28x28 image becomes a single 784 dimensional vector. We'll also scale the inputs to be in the range [0-1] rather than [0-255]"]},{"metadata":{"id":"gZpp03WBBn5S","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train = X_train.reshape(60000, 784)\n","X_test = X_test.reshape(10000, 784)\n","X_train = X_train.astype('float32') \n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","print(\"Training shape\", X_train.shape)\n","print(\"Testing shape\", X_test.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"25iicQrnBn5b","colab_type":"text"},"cell_type":"markdown","source":["Modify the target matrices to be in the one-hot format"]},{"metadata":{"id":"SC5k59GBBn5i","colab_type":"code","colab":{}},"cell_type":"code","source":["Y_train = np_utils.to_categorical(y_train, nb_classes)\n","Y_test = np_utils.to_categorical(y_test, nb_classes)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h7DwlZlBBn5n","colab_type":"text"},"cell_type":"markdown","source":["# Lab 1.1 Dense Layer"]},{"metadata":{"id":"d0Yptkf7Bn5p","colab_type":"text"},"cell_type":"markdown","source":["Lab 1.1 We only have dense layer.\n","\n","Dense layers are keras alias for Fully connected layers. These layers give the ability to classify the features learned by the CNN.\n","\n","Dense layers have 512 neurons and activation function is 'relu'.\n","\n","The last layer is the Dense layer with 10 neurons and activation function is Softmax . The neurons in this layer should be equal to the number of classes we want to predict as this is the output layer. \n","\n","function -> Dense(units , activation = 'activation')(previous_layer)\n"]},{"metadata":{"id":"cnfmZtxnBn5r","colab_type":"text"},"cell_type":"markdown","source":["If you create model success your model must have model.summary() like below :"]},{"metadata":{"id":"exyKoROWBn5t","colab_type":"text"},"cell_type":"markdown","source":["<!-- <img src=\"dense.PNG\"> -->\n","\n","![](https://i.imgur.com/wmaw5AI.png)"]},{"metadata":{"id":"7L0d7K-fBn5u","colab_type":"code","colab":{}},"cell_type":"code","source":["# create only dense layer\n","input_tensor = Input(shape = (784,))\n","\n","### To Do ###\n","\n","\n","\n","\n","######\n","\n","pred = Dense(10, activation = 'softmax')(previous_layer)\n","model = Model(inputs = input_tensor, outputs = pred)\n","model.compile(loss='categorical_crossentropy', optimizer='adam',\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Uc7WzhogBn50","colab_type":"code","colab":{}},"cell_type":"code","source":["history = model.fit(X_train, Y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vvUj7tkZBn59","colab_type":"code","colab":{}},"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dqgFi2BaBn6G","colab_type":"code","colab":{}},"cell_type":"code","source":["history_dict = history.history\n","history_dict.keys()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pZJybpMzBn6Q","colab_type":"code","colab":{}},"cell_type":"code","source":["loss_values = history_dict['loss']\n","val_loss_values = history_dict['val_loss']\n","epochs = range(1, len(loss_values) + 1)\n","\n","plt.plot(epochs, loss_values, 'ro', label='Training loss')\n","plt.plot(epochs, val_loss_values, 'b+', label='Validation loss')\n","plt.legend()\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6HtzRbAFBn6W","colab_type":"code","colab":{}},"cell_type":"code","source":["acc_values = history_dict['acc']\n","val_acc_values = history_dict['val_acc']\n","\n","plt.plot(epochs, acc_values, 'ro', label='Training accuracy')\n","plt.plot(epochs, val_acc_values, 'b+', label='Validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TBd1QXyABn6c","colab_type":"text"},"cell_type":"markdown","source":["# Lab1.2 Dense + Dropout Layer"]},{"metadata":{"id":"uOXPKJmNBn6e","colab_type":"text"},"cell_type":"markdown","source":["Lab 1.2 We have 2 dense layer and dropout layer.\n","\n","Dense layers have 512 neurons and activation function is 'relu'.\n","\n","Dropout is the method used to reduce overfitting. It forces the model to learn multiple independent representations of the same data by randomly disabling neurons in the learning phase. In our model, dropout will randomnly disable 20% of the neurons.\n","\n","The last layer is the Dense layer with 10 neurons and activation function is Softmax .\n","\n","\n","function -> Dense(units , activation = 'activation')(previous_layer)\n","\n","function -> Dropout(rate)(previous_layer)"]},{"metadata":{"id":"sjTX7BMjBn6g","colab_type":"text"},"cell_type":"markdown","source":["If you create model success your model must have model.summary() like below :"]},{"metadata":{"id":"MoLGGxDSBn6h","colab_type":"text"},"cell_type":"markdown","source":["<!-- <img src=\"dense+drop.PNG\"> -->\n","\n","![](https://i.imgur.com/G818tiC.png)"]},{"metadata":{"id":"wPVbOs5OBn6j","colab_type":"code","colab":{}},"cell_type":"code","source":["# create only dense + dropout layer\n","input_tensor = Input(shape = (784,))\n","\n","### To Do ###\n","\n","\n","\n","\n","######\n","\n","model = Model(inputs = input_tensor, outputs = pred)\n","model.compile(loss='categorical_crossentropy', optimizer='adam',\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7Ta5kQWKBn6p","colab_type":"code","colab":{}},"cell_type":"code","source":["history = model.fit(X_train, Y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"73QWXQtQBn6u","colab_type":"code","colab":{}},"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LcwwPDfDBn6z","colab_type":"code","colab":{}},"cell_type":"code","source":["history_dict = history.history\n","history_dict.keys()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xOqBzFZLBn69","colab_type":"code","colab":{}},"cell_type":"code","source":["loss_values = history_dict['loss']\n","val_loss_values = history_dict['val_loss']\n","epochs = range(1, len(loss_values) + 1)\n","\n","plt.plot(epochs, loss_values, 'ro', label='Training loss')\n","plt.plot(epochs, val_loss_values, 'b+', label='Validation loss')\n","plt.legend()\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bqC2AN_8Bn7C","colab_type":"code","colab":{}},"cell_type":"code","source":["acc_values = history_dict['acc']\n","val_acc_values = history_dict['val_acc']\n","\n","plt.plot(epochs, acc_values, 'ro', label='Training accuracy')\n","plt.plot(epochs, val_acc_values, 'b+', label='Validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WX3iP_zLBn7H","colab_type":"text"},"cell_type":"markdown","source":["# Lab 1.3 Convolutional Neural Network (CNN)\n","\n","We also need to specify the shape of the input which is (28, 28, 1), but we have to specify it only once.\n","\n","The second layer is the Activation layer. We have used ReLU (rectified linear unit) as our activation function. ReLU function is f(x) = max(0, x), where x is the input. It sets all negative values\n","\n","The third layer is the MaxPooling layer. MaxPooling layer is used to down-sample the input to enable the model to make assumptions about the features so as to reduce over-fitting\n","\n","After creating all the convolutional layers, we need to flatten them, so that they can act as an input to the Dense layers.\n","\n","Dense layers have 512 neurons and activation function is 'relu'.\n","\n","Dropout will randomnly disable 20% of the neurons.\n","\n","The last layer is the Dense layer with 10 neurons and activation function is Softmax . \n","\n","Our model have architecture belowing:"]},{"metadata":{"id":"zLHPaM4qBn7I","colab_type":"text"},"cell_type":"markdown","source":["![](https://pbs.twimg.com/media/DJDu-seXcAAvqZf.jpg:large)\n","\n","*(Source: https://twitter.com/DeepLearn007/status/905486345862344704)*"]},{"metadata":{"id":"jig6AMPxBn7J","colab_type":"text"},"cell_type":"markdown","source":["Try to create model like architecture.\n","\n","Function :\n","\n","    1. Conv2D(filters, kernel_size, activation = 'activation')(previous_layer)\n","    2. MaxPooling2D(pool_size)(previous_layer)\n","    3. Dropout(rate)(previous_layer)\n","    4. Flatten()(previous_layer)\n","    5. Dense(units , activation = 'activation')(previous_layer)"]},{"metadata":{"id":"BdaW5ILLBn7L","colab_type":"text"},"cell_type":"markdown","source":["If you create model success your model must have model.summary() like below :"]},{"metadata":{"id":"4SqrEdjPBn7O","colab_type":"text"},"cell_type":"markdown","source":["<!-- <img src=\"cnn.PNG\"> -->\n","\n","![](https://i.imgur.com/pqAwq0g.png)"]},{"metadata":{"id":"dXYnwLELBn7P","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train = X_train.reshape(60000, 28, 28, 1)\n","X_test = X_test.reshape(10000, 28 ,28 ,1)\n","X_train = X_train.astype('float32') \n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","print(\"Training shape\", X_train.shape)\n","print(\"Testing shape\", X_test.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"myuBgDGRBn7a","colab_type":"code","colab":{}},"cell_type":"code","source":["input_tensor = Input(shape = (28,28,1))\n","\n","### To Do ###\n","\n","\n","\n","\n","\n","\n","######\n","\n","model = Model(inputs = input_tensor, outputs = pred)\n","\n","model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X5XImTAGBn7d","colab_type":"code","colab":{}},"cell_type":"code","source":["early_stopping = EarlyStopping(patience=0, verbose=1)\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"scrolled":true,"id":"O98gogfVBn7f","colab_type":"code","colab":{}},"cell_type":"code","source":["history = model.fit(X_train, Y_train, batch_size=128, epochs=10,\n","                    verbose=1, validation_split=0.2,\n","                    callbacks = [early_stopping])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8wbKBFg7Bn7z","colab_type":"code","colab":{}},"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qQgGhPvhBn73","colab_type":"code","colab":{}},"cell_type":"code","source":["history_dict = history.history\n","\n","history_dict.keys()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tB76lXV_Bn77","colab_type":"code","colab":{}},"cell_type":"code","source":["loss_values = history_dict['loss']\n","val_loss_values = history_dict['val_loss']\n","epochs = range(1, len(loss_values) + 1)\n","\n","plt.plot(epochs, loss_values, 'ro', label='Training loss')\n","plt.plot(epochs, val_loss_values, 'b+', label='Validation loss')\n","plt.legend()\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XmGcbH7vBn79","colab_type":"code","colab":{}},"cell_type":"code","source":["acc_values = history_dict['acc']\n","val_acc_values = history_dict['val_acc']\n","\n","plt.plot(epochs, acc_values, 'ro', label='Training accuracy')\n","plt.plot(epochs, val_acc_values, 'b+', label='Validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xEn_pooCBn8A","colab_type":"text"},"cell_type":"markdown","source":["# Confusion matrix"]},{"metadata":{"id":"hBXEVWu4Bn8B","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","import itertools\n","def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes)\n","    plt.yticks(tick_marks, classes)\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","# Predict the values from the validation dataset\n","Y_pred = model.predict(X_test)\n","# Convert predictions classes to one hot vectors \n","Y_pred_classes = np.argmax(Y_pred, axis = 1) \n","# Convert validation observations to one hot vectors\n","Y_true = np.argmax(Y_test, axis = 1) \n","# compute the confusion matrix\n","confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n","# plot the confusion matrix\n","plot_confusion_matrix(confusion_mtx, classes = range(10))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ImKJnVqcBn8D","colab_type":"text"},"cell_type":"markdown","source":["# Inspecting the output"]},{"metadata":{"id":"LDsMCrSHBn8E","colab_type":"code","colab":{}},"cell_type":"code","source":["predicted = model.predict(X_test)\n","predicted_classes = np.argmax(predicted,axis=1)\n","correct_indices = np.nonzero(predicted_classes == y_test)[0]\n","incorrect_indices = np.nonzero(predicted_classes != y_test)[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rUyrZ2xkBn8G","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.rcParams['figure.figsize'] = (15,15) \n","plt.figure()\n","for i, correct in enumerate(correct_indices[:9]):\n","    plt.subplot(3,3,i+1)\n","    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n","    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_test[correct]))\n","\n","plt.figure()\n","for i, incorrect in enumerate(incorrect_indices[:9]):\n","    plt.subplot(3,3,i+1)\n","    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n","    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_test[incorrect]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TvoU2RdXBn8J","colab_type":"text"},"cell_type":"markdown","source":["# Feature Visualization"]},{"metadata":{"id":"MtVJtnYrBn8K","colab_type":"code","colab":{}},"cell_type":"code","source":["input_tensor = Input(shape = (28,28,1))\n","conv1 = Conv2D(32, kernel_size=3,activation = 'relu')(input_tensor)\n","conv2 = Conv2D(32, kernel_size=3,activation = 'relu')(conv1)\n","pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n","conv3 = Conv2D(64, kernel_size=3,activation = 'relu')(pool1)\n","conv4 = Conv2D(64, kernel_size=3,activation = 'relu')(conv3)\n","pool2 = MaxPooling2D(pool_size=(2,2))(conv4)\n","\n","flatten_layer = Flatten()(pool2)\n","\n","hidden_layer = Dense(512 , activation = 'relu')(flatten_layer)\n","drop_layer = Dropout(0.2)(hidden_layer)\n","\n","pred = Dense(10, activation = 'softmax')(drop_layer)\n","\n","model = Model(inputs = input_tensor, outputs = pred)\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h0UQYeaEBn8M","colab_type":"code","colab":{}},"cell_type":"code","source":["test = X_train[154]\n","\n","plt.rcParams['figure.figsize'] = (5,5) \n","plt.imshow(test.reshape(28,28), cmap='gray', interpolation='none')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jN8aCckpBn8O","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras import models\n","layer_outputs = [layer.output for layer in model.layers[1:7]]\n","activation_model = models.Model(input=model.input, output=layer_outputs)\n","activations = activation_model.predict(test.reshape(1,28,28,1))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pE6OOpS5Bn8R","colab_type":"code","colab":{}},"cell_type":"code","source":["model.layers[:7]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mRICWP_PBn8W","colab_type":"text"},"cell_type":"markdown","source":["# Visualization Conv2D"]},{"metadata":{"id":"rF-q1Jv3Bn8W","colab_type":"code","colab":{}},"cell_type":"code","source":["layer_names = []\n","for layer in model.layers[1:7]:\n","    layer_names.append(layer.name) \n","images_per_row = 16\n","for layer_name, layer_activation in zip(layer_names, activations):\n","    if layer_name.startswith('conv'):\n","        n_features = layer_activation.shape[-1]\n","        size = layer_activation.shape[1]\n","        n_cols = n_features // images_per_row\n","        display_grid = np.zeros((size * n_cols, images_per_row * size))\n","        for col in range(n_cols):\n","            for row in range(images_per_row):\n","                channel_image = layer_activation[0,:, :, col * images_per_row + row]\n","                channel_image -= channel_image.mean()\n","                channel_image /= channel_image.std()\n","                channel_image *= 64\n","                channel_image += 128\n","                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n","                display_grid[col * size : (col + 1) * size,\n","                             row * size : (row + 1) * size] = channel_image\n","        scale = 1. / size\n","        plt.figure(figsize=(scale * display_grid.shape[1],\n","                            scale * display_grid.shape[0]))\n","        plt.title(layer_name)\n","        plt.grid(False)\n","        plt.imshow(display_grid, aspect='auto', cmap='gray')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4m3fXuYmBn8Z","colab_type":"text"},"cell_type":"markdown","source":["# Visualization Max pooling2D"]},{"metadata":{"id":"O1zLnKnvBn8a","colab_type":"code","colab":{}},"cell_type":"code","source":["layer_names = []\n","for layer in model.layers[1:7]:\n","    layer_names.append(layer.name) \n","images_per_row = 16\n","for layer_name, layer_activation in zip(layer_names, activations):\n","    if layer_name.startswith('max'):\n","        n_features = layer_activation.shape[-1]\n","        size = layer_activation.shape[1]\n","        n_cols = n_features // images_per_row\n","        display_grid = np.zeros((size * n_cols, images_per_row * size))\n","        for col in range(n_cols):\n","            for row in range(images_per_row):\n","                channel_image = layer_activation[0,:, :, col * images_per_row + row]\n","                channel_image -= channel_image.mean()\n","                channel_image /= channel_image.std()\n","                channel_image *= 64\n","                channel_image += 128\n","                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n","                display_grid[col * size : (col + 1) * size,\n","                             row * size : (row + 1) * size] = channel_image\n","        scale = 1. / size\n","        plt.figure(figsize=(scale * display_grid.shape[1],\n","                            scale * display_grid.shape[0]))\n","        plt.title(layer_name)\n","        plt.grid(False)\n","        plt.imshow(display_grid, aspect='auto', cmap='gray')"],"execution_count":0,"outputs":[]}]}